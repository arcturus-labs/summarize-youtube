{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in /Users/johnberryman/projects/github/arcturus-labs/scratch/.venv/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/johnberryman/projects/github/arcturus-labs/scratch/.venv/lib/python3.13/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /Users/johnberryman/projects/github/arcturus-labs/scratch/.venv/lib/python3.13/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/johnberryman/projects/github/arcturus-labs/scratch/.venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/johnberryman/projects/github/arcturus-labs/scratch/.venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/johnberryman/projects/github/arcturus-labs/scratch/.venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/johnberryman/projects/github/arcturus-labs/scratch/.venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (2025.4.26)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "class Conversation:\n",
    "    def __init__(self, model):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "        \n",
    "    def say(self, message, hidden=False):\n",
    "        self.messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message\n",
    "            }\n",
    "        )\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            max_tokens=3000,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        # if response.choices[0].message.role == \"assistant\":\n",
    "        self.messages.append(response.choices[0].message)\n",
    "        if not hidden:\n",
    "            display(Markdown(response.choices[0].message.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi # pip install youtube-transcript-api\n",
    "\n",
    "class YouTubeConversation(Conversation):\n",
    "    def __init__(self, model, video_id):\n",
    "        super().__init__(model)\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "You are a video transcript summarizer. The video ID is {video_id}.\n",
    "\n",
    "Here is the video transcript which includes the timestamp in seconds (pay special attention to timestamps because you'll be asked about them later).\n",
    "\n",
    "---\n",
    "{YouTubeConversation._get_transcript(video_id)}\n",
    "---\n",
    "\n",
    "In subsequent conversation, if someone askes about a URL to a point in the video then use the standard YouTube URL format with the video ID and the timestamp in seconds, e.g., https://www.youtube.com/watch?v={video_id}&t=1234s.\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        self.say(\n",
    "            \"\"\"\\\n",
    "Create a quick summary of the video transcript above as a bulleted list of topics covered in time order. For each bullet, include the following:\n",
    "- the topic\n",
    "- a very terse summary of the topic (one sentence)\n",
    "- the timestamp (seconds, just like above) of the first occurrence of that topic along with the line of transcript that introduces the topic\n",
    "- the timestamp (seconds) of the most important part of the topic along with the line of transcript that introduces the topic\n",
    "\n",
    "This summary serves as a quick reference for later, but shouldn't influence the formal summary you'll be asked to write later which will be more detailed and prose-like.\n",
    "\"\"\",\n",
    "            hidden=True,\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def _get_transcript(cls, video_id):\n",
    "        data = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        transcript = []\n",
    "        for entry in data:\n",
    "            transcript.append(f\"{entry['start']}: {entry['text']}\")\n",
    "        return \"\\n\".join(transcript)\n",
    "    \n",
    "    def start(self):\n",
    "        self.say(f\"Provide a formal summary of the video transcript. Start with an introduction and then provide a summary of the topics covered in the video. This time write it as well-formatted markdown prose that is more comfortable to read. You can make use of markdown sections and subsections or bulleted lists - whichever is more appropriate for capturing the flow of the transcript. At appropriate points in the prose create YouTube URL links to the starting point of the segment you're discussing. These links do not have to include a quote from the transcript, but should be relevant to the topic being discussed. If you do decide to include a quote, then correct spelling and punctuation (the original transcript was all lowercase and had no punctuation).\")\n",
    "\n",
    "\n",
    "class YouTubeConversation2(Conversation):\n",
    "    def __init__(self, model, video_id):\n",
    "        super().__init__(model)\n",
    "        self.video_id = video_id\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "You are an advanced AI assistant specialized in summarizing YouTube video transcripts. Your task is to provide comprehensive, well-structured summaries that capture the essence of the video content. The video ID you're working with is {video_id}.\n",
    "\n",
    "Here is the complete video transcript, including timestamps in seconds:\n",
    "\n",
    "---\n",
    "{YouTubeConversation._get_transcript(video_id)}\n",
    "---\n",
    "\n",
    "Instructions for summarization:\n",
    "\n",
    "1. Quick Overview:\n",
    "   - Create a brief (2-3 sentences) overview of the video's main topic and purpose.\n",
    "\n",
    "2. Detailed Summary:\n",
    "   - Provide a detailed summary of the video content in well-formatted markdown prose.\n",
    "   - Use appropriate headings (##, ###) to structure the summary logically.\n",
    "   - Include 3-5 main sections, each covering a major topic or theme from the video.\n",
    "   - Within each section, use subsections or bullet points as needed to break down subtopics.\n",
    "\n",
    "3. Key Points and Timestamps:\n",
    "   - For each main section, identify 2-3 key points or moments.\n",
    "   - Create YouTube URL links for these key points using the format: https://www.youtube.com/watch?v={video_id}&t=X, where X is the timestamp in seconds.\n",
    "   - Briefly explain why each highlighted moment is significant.\n",
    "\n",
    "4. Notable Quotes:\n",
    "   - Include 2-3 notable quotes from the transcript, correcting spelling and punctuation as needed.\n",
    "   - Provide context for each quote and explain its relevance.\n",
    "\n",
    "5. Visual Elements (if mentioned in the transcript):\n",
    "   - Note any significant visual elements described in the transcript (e.g., charts, demonstrations, or visual aids).\n",
    "   - Explain how these visuals contribute to the video's message.\n",
    "\n",
    "6. Conclusion:\n",
    "   - Summarize the main takeaways from the video in 2-3 sentences.\n",
    "   - If applicable, mention any call-to-action or next steps suggested in the video.\n",
    "\n",
    "7. Metadata (at the end of the summary):\n",
    "   - Video Length: [HH:MM:SS] (calculate from the last timestamp)\n",
    "   - Main Topics: List 3-5 main topics covered\n",
    "   - Target Audience: Infer the likely target audience based on the content\n",
    "\n",
    "Remember to maintain a neutral tone and focus on accurately representing the video's content. Your summary should be informative and easy to navigate, allowing readers to quickly understand the video's content and locate specific information if needed.\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def _get_transcript(cls, video_id):\n",
    "        data = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        transcript = []\n",
    "        for entry in data:\n",
    "            transcript.append(f\"{entry['start']}: {entry['text']}\")\n",
    "        return \"\\n\".join(transcript)\n",
    "    \n",
    "    def start(self):\n",
    "        self.say(\"Please provide a comprehensive summary of the YouTube video transcript based on the instructions given. Ensure your summary is well-structured, informative, and easy to navigate.\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Video e9tL_Eg3fpM: The Evolution of Fast AI to Answer AI and the New Paradigm of Dialogue Engineering\n",
       "\n",
       "This video presents an in-depth conversation about the origins of Fast AI, its evolution into Answer AI, and the innovative educational approach and tools being developed to teach AI and coding. Jeremy Howard, co-founder of Fast AI and Answer AI, explains the motivations behind these projects, the shift in AI accessibility, and the novel concept of dialogue engineering that powers a new interactive learning platform called Solvit.\n",
       "\n",
       "---\n",
       "\n",
       "## Introduction: Origins and Vision of Fast AI\n",
       "\n",
       "Jeremy Howard begins by recounting why Fast AI was founded. The initial vision was driven by the recognition that AI is likely the most significant technology of the century, with profound societal impacts. However, there was a concern that if understanding and access to AI remained limited to a small group, it could exacerbate inequality and reduce opportunities for many. Conversely, broad access and education could enable more people to benefit from AI and contribute to shaping society's use of this technology.\n",
       "\n",
       "To address this, Fast AI was created to teach people how to use AI, particularly by training models and making AI more accessible, cheaper, and faster. The project also contributed foundational research, such as ULMFiT, which played a crucial role in modern language model development. This background sets the stage for the subsequent evolution of the initiative.  \n",
       "[Watch segment at 5s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=5s)\n",
       "\n",
       "---\n",
       "\n",
       "## Transition from Fast AI to Answer AI\n",
       "\n",
       "As AI technology advanced, particularly with the emergence of models like ChatGPT, the need to train your own models diminished. Jeremy explains that this shift allowed the team to aim higher with Answer AI, a new organization started with Eric Reese, to go beyond Fast AI's original scope. Answer AI focuses on enabling a much broader audience to use AI effectively without requiring deep coding or model training knowledge.\n",
       "\n",
       "This transition reflects both technological progress and a strategic pivot to democratize AI usage further.  \n",
       "[Watch segment at 150s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=150s)\n",
       "\n",
       "---\n",
       "\n",
       "## Expanding the Target Audience: From Coders to Everyone\n",
       "\n",
       "Previously, Fast AI’s primary audience was people already skilled in coding. With tools like ChatGPT, AI became accessible to a general audience who could leverage its power without technical expertise. Jeremy draws an analogy to the internet and the iPhone, suggesting that ChatGPT brought AI to most people's fingertips in a similar way.\n",
       "\n",
       "The goal now is to teach everyone how to use AI effectively, though coding skills still offer significant advantages. This broadening of the audience is a core driver behind the new educational initiatives.  \n",
       "[Watch segment at 210s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=210s)\n",
       "\n",
       "---\n",
       "\n",
       "## Integration of Fast AI into Answer AI and New Educational Offerings\n",
       "\n",
       "Fast AI has been incorporated into Answer AI, gaining access to more resources and funding. Out of this integration, a new type of course has been developed—one that leverages AI not only as a subject but as an integral part of the learning process itself.\n",
       "\n",
       "Jeremy highlights that this course is unique and only possible now with AI’s capabilities. It focuses on teaching people how to solve problems using a combination of code and AI, a skill set previously inaccessible to many.  \n",
       "[Watch segment at 303s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=303s)\n",
       "\n",
       "---\n",
       "\n",
       "## A New Learning Process: Embedding AI into Education\n",
       "\n",
       "The new course model differs significantly from traditional teaching methods. Rather than AI being a small side tool, it is embedded deeply into the curriculum and learning experience. This means AI is part of how concepts are taught and how students engage with problems.\n",
       "\n",
       "This approach is described as a paradigm shift in education, aiming to make AI a fundamental element of learning rather than an add-on.  \n",
       "[Watch segment at 527s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=527s)\n",
       "\n",
       "---\n",
       "\n",
       "## The Power of Combining Coding and AI\n",
       "\n",
       "Jeremy explains why combining coding skills with AI is especially powerful. While AI tools like ChatGPT can generate solutions, they often require iterative human refinement. By writing some code yourself and working interactively with AI, you can break down problems, modify AI outputs, and build up solutions incrementally.\n",
       "\n",
       "This interactive process, where human creativity and AI's knowledge base work together, is far more effective than relying solely on AI-generated code.  \n",
       "[Watch segment at 674s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=674s)\n",
       "\n",
       "---\n",
       "\n",
       "## Limitations of AI-Only Code Generation and the Need for Human Input\n",
       "\n",
       "Language models currently tend to produce overly complex or generic code that may not fit the specific problem well. The video stresses that AI alone cannot yet generate high-quality, concise code reliably.\n",
       "\n",
       "The solution is an interactive workflow where humans write, test, and understand small chunks of code, with AI assisting in the process. This method leads to better quality, more maintainable code and deeper understanding.  \n",
       "[Watch segment at 1303s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=1303s)\n",
       "\n",
       "---\n",
       "\n",
       "## Advantages of an Interactive Coding Workflow\n",
       "\n",
       "Though building code one or two lines at a time may seem slower initially, Jeremy compares it to teaching a child math fundamentals rather than just how to use a calculator. This foundational learning leads to greater long-term speed, understanding, and problem-solving ability.\n",
       "\n",
       "This incremental approach prevents users from hitting frustrating walls caused by complexity or lack of understanding.  \n",
       "[Watch segment at 1410s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=1410s)\n",
       "\n",
       "---\n",
       "\n",
       "## Challenges Faced by New Coders Relying on AI Alone\n",
       "\n",
       "Jeremy shares observations about beginners who quickly build simple projects using AI but then get stuck when problems become more complex. These users often become discouraged and embarrassed when their projects fail or become unmanageable.\n",
       "\n",
       "This highlights the importance of teaching coding skills alongside AI use to sustain progress and confidence.  \n",
       "[Watch segment at 970s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=970s)\n",
       "\n",
       "---\n",
       "\n",
       "## Dialogue Engineering: A New Paradigm for Human-AI Interaction\n",
       "\n",
       "One of the most innovative concepts introduced is **dialogue engineering**, a new way of working with AI models. Unlike prompt engineering, dialogue engineering involves an ongoing, dynamic feedback loop where the user and AI assist each other step-by-step.\n",
       "\n",
       "This approach unlocks new levels of problem-solving complexity and makes AI collaboration more productive and adaptive.  \n",
       "[Watch segment at 1668s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=1668s)\n",
       "\n",
       "---\n",
       "\n",
       "## Solvit: A Platform Supporting Dialogue Engineering\n",
       "\n",
       "The team developed **Solvit**, a platform designed specifically to facilitate dialogue engineering. Instead of generating large blocks of code in one go, Solvit encourages a back-and-forth interaction where AI and human write small pieces of code alternately.\n",
       "\n",
       "This leads to clearer, more efficient code tailored to the user’s environment and needs. Solvit supports workflows favored by expert developers and enables learners to build understanding as they go.  \n",
       "[Watch segment at 1178s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=1178s)\n",
       "\n",
       "---\n",
       "\n",
       "## Sharing Dialogues to Foster Collaboration and Understanding\n",
       "\n",
       "An important advantage of dialogue engineering is that the entire process—the prompts, responses, code changes—is recorded as a dialogue. Sharing these dialogues within a team or community helps others understand not just the final code but the reasoning and decisions behind it.\n",
       "\n",
       "This transparency improves collaboration, knowledge transfer, and future code maintenance.  \n",
       "[Watch segment at 2143s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=2143s)\n",
       "\n",
       "---\n",
       "\n",
       "## Future Directions and the Potential of Dialogue Engineering\n",
       "\n",
       "Jeremy outlines ambitious plans to expand this educational and tooling approach. Future courses could cover full-stack startup engineering, system administration, marketing automation, and more—all powered by dialogue engineering.\n",
       "\n",
       "The approach is already proven internally at Answer AI, showing how a small team can achieve extraordinary results quickly by combining human creativity with AI assistance.  \n",
       "[Watch segment at 2400s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=2400s)\n",
       "\n",
       "---\n",
       "\n",
       "## Conclusion: Human-AI Collaboration as a Superpower\n",
       "\n",
       "The video closes with reflections on how integrating AI into the coding process grants users \"superpowers.\" Jeremy emphasizes that neither humans nor AI alone can achieve what they can together through dialogue engineering and interactive workflows.\n",
       "\n",
       "This human-plus-AI collaboration represents a transformative step in learning, coding, and problem-solving, opening new possibilities for individuals and organizations alike.  \n",
       "[Watch segment at 2371s](https://www.youtube.com/watch?v=e9tL_Eg3fpM&t=2371s)\n",
       "\n",
       "---\n",
       "\n",
       "This comprehensive discussion highlights a shift in AI education and practice, from isolated coding or AI use toward a blended, interactive, and collaborative model that empowers a much wider audience to solve complex problems effectively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = YouTubeConversation(\"gpt-4.1-mini\", \"e9tL_Eg3fpM\")\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the points in the video transcript where the term 'Agent' was defined or discussed, along with timestamped YouTube links:\n",
       "\n",
       "1. **Initial Definition of Agents**  \n",
       "   Swix provides a slide defining what an agent is, focusing on machine learning, AI, and software engineering perspectives.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=1259s).\n",
       "\n",
       "2. **Expanded Definition by Simon Willison**  \n",
       "   An expanded definition of agents is discussed, featuring crowdsource input from Simon Willison.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=1285s).\n",
       "\n",
       "3. **OpenAI's New Definition of Agents**  \n",
       "   The presentation mentions a new definition of agents released by OpenAI during the summit.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=1340s)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c.say(\"List all of the places where 'Agent' was defined in the transcript. Give me timestampped links.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Here is a list of all the places throughout the transcript where 'Agent' is defined or discussed, along with the corresponding timestamped links:\n",
       "\n",
       "1. **Initial Definition by Swix**  \n",
       "   Swix provides a slide defining what an agent is, focusing on machine learning, AI, and software engineering perspectives.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=1259s).\n",
       "\n",
       "2. **Expanded Definition by Simon Willison**  \n",
       "   An expanded definition of agents is discussed, featuring crowdsource input from Simon Willison.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=1285s).\n",
       "\n",
       "3. **OpenAI's New Definition of Agents**  \n",
       "   The presentation mentions a new definition of agents released by OpenAI during the summit.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=1340s).\n",
       "\n",
       "4. **Anthropic's Take on Agents**  \n",
       "   Barry Jang from Anthropic discusses their perspective on what constitutes an effective agent in their session.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=3749s).\n",
       "\n",
       "5. **Sierra's Definition of Agents**  \n",
       "   During the Sierra presentation, there's a discussion on how they conceptualize agents for their consumer brand products.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=4646s).\n",
       "\n",
       "6. **Bloomberg's Agent Architecture**  \n",
       "   The session on Bloomberg discusses how they define and use agents within their financial products and services.  \n",
       "   [Watch here](https://www.youtube.com/watch?v=D7BzTxVVMuw&t=11457s).\n",
       "\n",
       "These definitions and discussions provide various perspectives on what constitutes an agent and highlight the diversity of thought in the field."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c.say(\"No, list all of the definitions throught the transcript. This was only the first few minutes of the video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "🚀 Struggling to keep up with the rapid changes in AI? Discover how to harness the exponential growth in creativity and turn it into your superpower! 💡✨ Dive into the future of AI with John Berryman. Watch now: [https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235](https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235) #AI #Innovation #MachineLearning #Creativity"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c2.say(\"Come up with a Twitter post that make people want to watch the video. It should tug on a pain point from the video and link to a point in the video where I discuss it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Here are a few candidate ideas for hooks, each followed by a double-post format:\n",
       "\n",
       "### Candidate 1: The Challenge of Keeping Up\n",
       "**Post 1 (Teaser):**  \n",
       "Feeling overwhelmed by the fast-paced advancements in AI? It's a common struggle for many trying to stay ahead in this evolving landscape.\n",
       "\n",
       "**Post 2 (Link):**  \n",
       "Join John Berryman as he shares insights on leveraging the exponential growth in creativity to gain an edge. Watch here: [https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235](https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235)\n",
       "\n",
       "---\n",
       "\n",
       "### Candidate 2: Transforming Fear into Opportunity\n",
       "**Post 1 (Teaser):**  \n",
       "Does the rapid pace of AI development leave you anxious about the future? You're not alone—many feel the same pressure.\n",
       "\n",
       "**Post 2 (Link):**  \n",
       "Discover how to turn that fear into a creative advantage with John Berryman's strategies. Dive in: [https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235](https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235)\n",
       "\n",
       "---\n",
       "\n",
       "### Candidate 3: Mastering AI Tools\n",
       "**Post 1 (Teaser):**  \n",
       "Are AI tools leaving you feeling outmatched and underprepared? It's a familiar challenge in today's tech-driven world.\n",
       "\n",
       "**Post 2 (Link):**  \n",
       "Learn how to master these tools and enhance your creativity with insights from John Berryman. See more: [https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235](https://www.youtube.com/watch?v=60HAtHVBYj8&t=2235)\n",
       "\n",
       "Please let me know if you need further adjustments or another set of ideas!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c2.say(\"That's not bad. Let's remove the emojis and hashtags, and try to make it as 2 posts. The first one should be a teaser with the problem, and the second should link out to the particular point in the video where I discuss it. Actually - do this first, create a few candidate ideas for the the hook (problem, engaging conversation point) and then for each write a doublep-post like I just said.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
